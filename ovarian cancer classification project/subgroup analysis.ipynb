{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, RocCurveDisplay, roc_curve,auc, precision_recall_curve, average_precision_score, f1_score, auc \n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import json\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "import shap\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_theme()\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "    \n",
    "    X_train = pd.read_csv(f'/camin1/chlee/jupyter/ML project/[24-12-13]/Data/X_train/X_train_{i}.csv')\n",
    "    X_test = pd.read_csv(f'/camin1/chlee/jupyter/ML project/[24-12-13]/Data/X_test/X_test_{i}.csv')    \n",
    "    y_train = pd.read_csv(f'/camin1/chlee/jupyter/ML project/[24-12-13]/Data/y_train/y_train_{i}.csv')\n",
    "    y_test = pd.read_csv(f'/camin1/chlee/jupyter/ML project/[24-12-13]/Data/y_test/y_test_{i}.csv')\n",
    "\n",
    "    globals()[f'X_train_{i}'] = X_train.drop(X_train.columns[0], axis=1)\n",
    "    globals()[f'X_test_{i}'] = X_test.drop(X_test.columns[0], axis=1)\n",
    "    globals()[f'y_train_{i}'] = y_train.drop(y_train.columns[0], axis=1)\n",
    "    globals()[f'y_test_{i}'] = y_test.drop(y_test.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgroup analysis - highrisk group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "    \n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "    \n",
    "    X_train = X_train[X_train['FAMILY_HISTORY']==1][['AGE','MP_OXC','FHXNG','BRCACC_1','BRCACC_2','BMIG']]\n",
    "    X_test = X_test[X_test['FAMILY_HISTORY']==1][['AGE','MP_OXC','FHXNG','BRCACC_1','BRCACC_2','BMIG']]\n",
    "\n",
    "    y_train = y_train.iloc[X_train.index]\n",
    "    y_test = y_test.iloc[X_test.index]\n",
    "    \n",
    "\n",
    "    X_train.reset_index(drop=True, inplace=True)\n",
    "    X_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    globals()[f'X_train_{i}'] = X_train\n",
    "    globals()[f'X_test_{i}'] = X_test\n",
    "    \n",
    "    y_train.reset_index(drop=True)\n",
    "    y_test.reset_index(drop=True)\n",
    "    \n",
    "    globals()[f'y_train_{i}'] = y_train\n",
    "    globals()[f'y_test_{i}'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_cv(search_space):\n",
    "    model = LogisticRegression(solver = search_space['solver'],\n",
    "                               max_iter = search_space['max_iter'],\n",
    "                               random_state=42)\n",
    "    \n",
    "    skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        age_mean = np.mean(X_train_fold['AGE'])\n",
    "        age_std = np.std(X_train_fold['AGE'])\n",
    "        \n",
    "        X_train_fold['AGE'] = (X_train_fold['AGE'] - age_mean) / age_std\n",
    "        X_val_fold['AGE'] = (X_val_fold['AGE'] - age_mean) / age_std\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_pred_probs = model.predict_proba(X_val_fold)[:,1]\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return {'loss': -np.mean(accuracies), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
    "    'max_iter': hp.choice('max_iter', range(100,1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    print(f'{i}th loop')\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "    \n",
    "    trials = Trials()\n",
    "    \n",
    "    LR_ho = fmin(\n",
    "        fn = LR_cv,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 30,\n",
    "        trials = trials\n",
    "    )\n",
    "    globals()[f'LR_ho_{i}'] = LR_ho\n",
    "    LR_ho['max_iter'] = int(LR_ho['max_iter'])\n",
    "    LR_ho['solver'] = int(LR_ho['solver'])\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/LR/LR_ho_{i}.json', 'w') as f:\n",
    "        data = {key: value for key, value in LR_ho.items()}\n",
    "        json.dump(data, f)\n",
    "    print(LR_ho)\n",
    "            \n",
    "    solver_option = ['newton-cg', 'lbfgs', 'liblinear'][LR_ho['solver']]\n",
    "    \n",
    "    fit_LR = LogisticRegression(tol = 1e-4,\n",
    "                                solver = solver_option,\n",
    "                                max_iter = LR_ho['max_iter'],\n",
    "                                random_state=42)\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])    \n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_LR.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = fit_LR.predict(X_test)\n",
    "    y_pred_probs = fit_LR.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print('>>>> ROC_AUC score after hyperparameter tuning:' f\"{roc_auc_score(y_test, y_pred_probs):.3f}\")\n",
    "    print('>>>> accuracy after hyperparameter tuning:', f\"{accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(search_space):\n",
    "    model = RandomForestClassifier(max_depth = int(search_space['max_depth']),\n",
    "                                   min_samples_leaf = search_space['min_samples_leaf'],\n",
    "                                   n_estimators = 100,\n",
    "                                   random_state=42)\n",
    "   \n",
    "    skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    \n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        age_mean = np.mean(X_train_fold['AGE'])\n",
    "        age_std = np.std(X_train_fold['AGE'])\n",
    "        \n",
    "        X_train_fold['AGE'] = (X_train_fold['AGE'] - age_mean) / age_std\n",
    "        X_val_fold['AGE'] = (X_val_fold['AGE'] - age_mean) / age_std\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_pred_probs = model.predict_proba(X_val_fold)[:,1]\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return {'loss': -np.mean(accuracies), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    print(f'{i}th loop')\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "    \n",
    "    trials = Trials()\n",
    "    \n",
    "    rf_ho = fmin(\n",
    "        fn = rf_cv,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 30,\n",
    "        trials = trials\n",
    "    )\n",
    "    globals()[f'rf_ho_{i}'] = rf_ho\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/RF/rf_ho_{i}.json', 'w') as f:\n",
    "        data = {key: value for key, value in rf_ho.items()}\n",
    "        json.dump(data, f)\n",
    "    print(rf_ho)\n",
    "    \n",
    "    fit_rf = RandomForestClassifier(max_depth=int(rf_ho['max_depth']),\n",
    "                                    min_samples_leaf = rf_ho['min_samples_leaf'],\n",
    "                                    n_estimators = 100,\n",
    "                                    random_state=42)\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])    \n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = fit_rf.predict(X_test)\n",
    "    y_pred_probs = fit_rf.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print('>>>> ROC_AUC score after hyperparameter tuning:' f\"{roc_auc_score(y_test, y_pred_probs):.3f}\")\n",
    "    print('>>>> accuracy after hyperparameter tuning:', f\"{accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_cv(search_space):\n",
    "    model = xgb.XGBClassifier(max_depth = int(search_space['max_depth']),\n",
    "                              learning_rate = search_space['learning_rate'],\n",
    "                              n_estimators = 100,\n",
    "                              gamma = search_space['gamma'],\n",
    "                              min_child_weight = search_space['min_child_weight'],\n",
    "                              max_delta_step = search_space['max_delta_step'],\n",
    "                              subsample = search_space['subsample'],\n",
    "                              colsample_bytree = search_space['colsample_bytree'],\n",
    "                              scale_pos_weight = search_space['scale_pos_weight'],\n",
    "                              seed=42)\n",
    "        \n",
    "    skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        age_mean = np.mean(X_train_fold['AGE'])\n",
    "        age_std = np.std(X_train_fold['AGE'])\n",
    "        \n",
    "        X_train_fold['AGE'] = (X_train_fold['AGE'] - age_mean) / age_std\n",
    "        X_val_fold['AGE'] = (X_val_fold['AGE'] - age_mean) / age_std\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_pred_probs = model.predict_proba(X_val_fold)[:,1]\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return {'loss': -np.mean(accuracies), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 7, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.1, 0.01),\n",
    "    'gamma': hp.quniform('gamma', 0, 1, 0.1),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 4, 1),\n",
    "    'max_delta_step': hp.quniform('max_delta_step', 5, 9, 1),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.1),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.1),\n",
    "    'scale_pos_weight': hp.quniform('scale_pos_weight', 2, 6, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    print(f'{i}th loop')\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "    \n",
    "    trials = Trials()\n",
    "    \n",
    "    xgb_ho = fmin(\n",
    "        fn = XGB_cv,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 30,\n",
    "        trials = trials\n",
    "    )\n",
    "    globals()[f'xgb_ho_{i}'] = xgb_ho\n",
    "\n",
    "    with open(f'C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/hyperparameters/XGB/xgb_ho_{i}.json', 'w') as f:\n",
    "        data = {key: value for key, value in xgb_ho.items()}\n",
    "        json.dump(data, f)\n",
    "    print(xgb_ho)\n",
    "            \n",
    "    fit_xgb = xgb.XGBClassifier(max_depth= int(xgb_ho['max_depth']),\n",
    "                             learning_rate=xgb_ho['learning_rate'],\n",
    "                             n_estimators=100,\n",
    "                             gamma= xgb_ho['gamma'],\n",
    "                             min_child_weight=xgb_ho['min_child_weight'],\n",
    "                             max_delta_step=xgb_ho['max_delta_step'],\n",
    "                             subsample=xgb_ho['subsample'],\n",
    "                             colsample_bytree=xgb_ho['colsample_bytree'],\n",
    "                             scale_pos_weight=xgb_ho['scale_pos_weight'])\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])    \n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = fit_xgb.predict(X_test)\n",
    "    y_pred_probs = fit_xgb.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print('>>>> ROC_AUC score after hyperparameter tuning:' f\"{roc_auc_score(y_test, y_pred_probs):.3f}\")\n",
    "    print('>>>> accuracy after hyperparameter tuning:', f\"{accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catboost_cv(search_space):\n",
    "    model = CatBoostClassifier(max_depth = int(search_space['max_depth']),\n",
    "                               learning_rate = search_space['learning_rate'],\n",
    "                               n_estimators = 100,\n",
    "                               min_child_samples = int(search_space['min_child_samples']),\n",
    "                               subsample = search_space['subsample'],\n",
    "                               colsample_bylevel = search_space['colsample_bylevel'],\n",
    "                               scale_pos_weight = search_space['scale_pos_weight'],\n",
    "                               random_seed=42,\n",
    "                               logging_level = \"Silent\")\n",
    "        \n",
    "    skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        age_mean = np.mean(X_train_fold['AGE'])\n",
    "        age_std = np.std(X_train_fold['AGE'])\n",
    "        \n",
    "        X_train_fold['AGE'] = (X_train_fold['AGE'] - age_mean) / age_std\n",
    "        X_val_fold['AGE'] = (X_val_fold['AGE'] - age_mean) / age_std\n",
    "        \n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        y_pred_probs = model.predict_proba(X_val_fold)[:,1]\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return {'loss': -np.mean(accuracies), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': hp.quniform('max_depth', 1, 7, 1),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.01, 0.1, 0.01),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 10, 40, 10),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.1),\n",
    "    'colsample_bylevel': hp.quniform('colsample_bylevel', 0.4, 1, 0.1),\n",
    "    'scale_pos_weight': hp.quniform('scale_pos_weight', 2, 6, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    print(f'{i}th loop')\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "    \n",
    "    trials = Trials()\n",
    "    \n",
    "    catboost_ho = fmin(\n",
    "        fn = catboost_cv,\n",
    "        space = search_space,\n",
    "        algo = tpe.suggest,\n",
    "        max_evals = 30,\n",
    "        trials = trials\n",
    "    )\n",
    "    globals()[f'catboost_ho_{i}'] = catboost_ho\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/Catboost/catboost_ho_{i}.json', 'w') as f:\n",
    "        data = {key: value for key, value in catboost_ho.items()}\n",
    "        json.dump(data, f)\n",
    "    print(catboost_ho)\n",
    "            \n",
    "    fit_catboost = CatBoostClassifier(max_depth= int(catboost_ho['max_depth']),\n",
    "                                      learning_rate=catboost_ho['learning_rate'],\n",
    "                                      n_estimators=100,\n",
    "                                      min_child_samples = int(catboost_ho['min_child_samples']),\n",
    "                                      subsample=catboost_ho['subsample'],\n",
    "                                      colsample_bylevel=catboost_ho['colsample_bylevel'],\n",
    "                                      scale_pos_weight=catboost_ho['scale_pos_weight'],\n",
    "                                      logging_level=\"Silent\")\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])    \n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_catboost.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = fit_catboost.predict(X_test)\n",
    "    y_pred_probs = fit_catboost.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    print('>>>> ROC_AUC score after hyperparameter tuning:' f\"{roc_auc_score(y_test, y_pred_probs):.3f}\")\n",
    "    print('>>>> accuracy after hyperparameter tuning:', f\"{accuracy_score(y_test, y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import model pickle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/LR/LR_ho_{i}.json', 'r') as data: #####\n",
    "        LR_ho = json.load(data)\n",
    "\n",
    "    solver_option = ['newton-cg', 'lbfgs', 'liblinear'][LR_ho['solver']]\n",
    "    \n",
    "    fit_LR = LogisticRegression(tol = 1e-4,\n",
    "                                solver = solver_option,\n",
    "                                max_iter = LR_ho['max_iter'],\n",
    "                                random_state=42)    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_LR.fit(X_train, y_train)\n",
    "    pickle.dump(fit_LR, open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/LR/fit_LR_{i}.pkl', 'wb')) #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/RF/rf_ho_{i}.json', 'r') as data: #####\n",
    "        rf_ho = json.load(data)\n",
    "                \n",
    "    fit_rf = RandomForestClassifier(max_depth=int(rf_ho['max_depth']),\n",
    "                                    min_samples_leaf = rf_ho['min_samples_leaf'],\n",
    "                                    n_estimators = 100,\n",
    "                                    random_state=42)\n",
    "\n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "    \n",
    "    fit_rf.fit(X_train, y_train)\n",
    "    pickle.dump(fit_rf, open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/RF/fit_rf_{i}.pkl', 'wb')) #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    with open(f'C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/hyperparameters/XGB/xgb_ho_{i}.json', 'r') as data: #####\n",
    "        xgb_ho = json.load(data)\n",
    "\n",
    "    fit_xgb = xgb.XGBClassifier(max_depth= int(xgb_ho['max_depth']),\n",
    "                             learning_rate=xgb_ho['learning_rate'],\n",
    "                             n_estimators=100,\n",
    "                             gamma= xgb_ho['gamma'],\n",
    "                             min_child_weight=xgb_ho['min_child_weight'],\n",
    "                             max_delta_step=xgb_ho['max_delta_step'],\n",
    "                             subsample=xgb_ho['subsample'],\n",
    "                             colsample_bytree=xgb_ho['colsample_bytree'],\n",
    "                             scale_pos_weight=xgb_ho['scale_pos_weight'])\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_xgb.fit(X_train, y_train)\n",
    "    pickle.dump(fit_xgb, open(f'C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/model pkl save/XGB/fit_xgb_{i}.pkl', 'wb')) #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    with open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/hyperparameters/Catboost/catboost_ho_{i}.json', 'r') as data: #####\n",
    "        catboost_ho = json.load(data)\n",
    "\n",
    "    fit_catboost = CatBoostClassifier(max_depth= int(catboost_ho['max_depth']),\n",
    "                                      learning_rate=catboost_ho['learning_rate'],\n",
    "                                      n_estimators=100,\n",
    "                                      min_child_samples = int(catboost_ho['min_child_samples']),\n",
    "                                      subsample=catboost_ho['subsample'],\n",
    "                                      colsample_bylevel=catboost_ho['colsample_bylevel'],\n",
    "                                      scale_pos_weight=catboost_ho['scale_pos_weight'],\n",
    "                                      logging_level=\"Silent\")\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "        \n",
    "    fit_catboost.fit(X_train, y_train)\n",
    "    pickle.dump(fit_catboost, open(f'/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/Catboost/fit_catboost_{i}.pkl', 'wb')) #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model\n",
    "for i in range(1,30+1):\n",
    "    globals()[f'fit_LR_{i}'] = pickle.load(open(f\"/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/LR/fit_LR_{i}.pkl\", 'rb'))\n",
    "    globals()[f'fit_rf_{i}'] = pickle.load(open(f\"/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/RF/fit_rf_{i}.pkl\", 'rb'))\n",
    "    globals()[f'fit_catboost_{i}'] = pickle.load(open(f\"/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/Catboost/fit_catboost_{i}.pkl\", 'rb'))\n",
    "    globals()[f'fit_xgb_{i}'] = pickle.load(open(f\"/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/XGB/fit_xgb_{i}.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_LR = []\n",
    "AUROC_LR = []\n",
    "AP_LR = []\n",
    "Sensitivity_LR = []\n",
    "Specificity_LR = []\n",
    "Youden_LR = []\n",
    "f1_LR = []\n",
    "gmean_LR = []\n",
    "\n",
    "\n",
    "LR_fpr_ = []\n",
    "LR_tpr_ = []\n",
    "LR_roc_auc_ = []\n",
    "\n",
    "LR_precision_ = []\n",
    "LR_recall_ = []\n",
    "LR_ap_ = []\n",
    "    \n",
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    exec(f'model = fit_LR_{i}')\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "    \n",
    "    y_pred_probs = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1score = f1_score(y_test, y_pred, average='binary')\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "    Accuracy_LR.append(accuracy_score(y_test, y_pred))\n",
    "    AUROC_LR.append(roc_auc_score(y_test, y_pred_probs))\n",
    "    AP_LR.append(average_precision_score(y_test, y_pred_probs))\n",
    "    Sensitivity_LR.append(sensitivity)\n",
    "    Specificity_LR.append(specificity)\n",
    "    Youden_LR.append(youden_index)\n",
    "    f1_LR.append(f1score)\n",
    "    gmean_LR.append(gmean)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    LR_fpr_.append(fpr)\n",
    "    LR_tpr_.append(tpr)\n",
    "    LR_roc_auc_.append(roc_auc)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    average_precision = average_precision_score(y_test, y_pred_probs)\n",
    "\n",
    "    LR_precision_.append(precision)\n",
    "    LR_recall_.append(recall)\n",
    "    LR_ap_.append(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m, acc_h = np.round(mean_confidence_interval(Accuracy_LR),3)\n",
    "spe_m, spe_h = np.round(mean_confidence_interval(Specificity_LR),3)\n",
    "sen_m, sen_h = np.round(mean_confidence_interval(Sensitivity_LR),3)\n",
    "f1_m, f1_h = np.round(mean_confidence_interval(f1_LR),3)\n",
    "auroc_m, auroc_h = np.round(mean_confidence_interval(AUROC_LR),3)\n",
    "ap_m, ap_h = np.round(mean_confidence_interval(AP_LR),3)\n",
    "gmean_m, gmean_h = np.round(mean_confidence_interval(gmean_LR),3)\n",
    "\n",
    "# 신뢰구간\n",
    "print(acc_m,'±', acc_h)\n",
    "print(spe_m,'±', spe_h)\n",
    "print(sen_m,'±', sen_h)\n",
    "print(f1_m,'±', f1_h)\n",
    "print(auroc_m,'±', auroc_h)\n",
    "print(ap_m,'±', ap_h)\n",
    "print(gmean_m,'±', gmean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_RF = []\n",
    "AUROC_RF = []\n",
    "AP_RF = []\n",
    "Sensitivity_RF = []\n",
    "Specificity_RF = []\n",
    "Youden_RF = []\n",
    "f1_RF = []\n",
    "gmean_RF = []\n",
    "\n",
    "rf_fpr_ = []\n",
    "rf_tpr_ = []\n",
    "rf_roc_auc_ = []\n",
    "\n",
    "rf_precision_ = []\n",
    "rf_recall_ = []\n",
    "rf_ap_ = []\n",
    "    \n",
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    exec(f'model = fit_rf_{i}')\n",
    "    \n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "    \n",
    "    y_pred_probs = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1score = f1_score(y_test, y_pred, average='binary')\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "    Accuracy_RF.append(accuracy_score(y_test, y_pred))\n",
    "    AUROC_RF.append(roc_auc_score(y_test, y_pred_probs))\n",
    "    AP_RF.append(average_precision_score(y_test, y_pred_probs))\n",
    "    Sensitivity_RF.append(sensitivity)\n",
    "    Specificity_RF.append(specificity)\n",
    "    Youden_RF.append(youden_index)\n",
    "    f1_RF.append(f1score)\n",
    "    gmean_RF.append(gmean)\n",
    "\n",
    "    # for auroc curve and precision call\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    rf_fpr_.append(fpr)\n",
    "    rf_tpr_.append(tpr)\n",
    "    rf_roc_auc_.append(roc_auc)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    average_precision = average_precision_score(y_test, y_pred_probs)\n",
    "\n",
    "    rf_precision_.append(precision)\n",
    "    rf_recall_.append(recall)\n",
    "    rf_ap_.append(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m, acc_h = np.round(mean_confidence_interval(Accuracy_RF),3)\n",
    "spe_m, spe_h = np.round(mean_confidence_interval(Specificity_RF),3)\n",
    "sen_m, sen_h = np.round(mean_confidence_interval(Sensitivity_RF),3)\n",
    "f1_m, f1_h = np.round(mean_confidence_interval(f1_RF),3)\n",
    "auroc_m, auroc_h = np.round(mean_confidence_interval(AUROC_RF),3)\n",
    "ap_m, ap_h = np.round(mean_confidence_interval(AP_RF),3)\n",
    "gmean_m, gmean_h = np.round(mean_confidence_interval(gmean_RF),3)\n",
    "\n",
    "# 신뢰구간\n",
    "print(acc_m,'±', acc_h)\n",
    "print(spe_m,'±', spe_h)\n",
    "print(sen_m,'±', sen_h)\n",
    "print(f1_m,'±', f1_h)\n",
    "print(auroc_m,'±', auroc_h)\n",
    "print(ap_m,'±', ap_h)\n",
    "print(gmean_m,'±', gmean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_XGB = []\n",
    "AUROC_XGB = []\n",
    "AP_XGB = []\n",
    "Sensitivity_XGB = []\n",
    "Specificity_XGB = []\n",
    "Youden_XGB = []\n",
    "f1_XGB = []\n",
    "gmean_XGB = []\n",
    "    \n",
    "xgb_fpr_ = []\n",
    "xgb_tpr_ = []\n",
    "xgb_roc_auc_ = []\n",
    "    \n",
    "xgb_precision_ = []\n",
    "xgb_recall_ = []\n",
    "xgb_ap_ = []\n",
    "\n",
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "    \n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    exec(f'model = fit_xgb_{i}')\n",
    "\n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "    \n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "    \n",
    "    y_pred_probs = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "        \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1score = f1_score(y_test, y_pred, average='binary')\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    Accuracy_XGB.append(accuracy_score(y_test, y_pred))\n",
    "    AUROC_XGB.append(roc_auc_score(y_test, y_pred_probs))\n",
    "    AP_XGB.append(average_precision_score(y_test, y_pred_probs))\n",
    "    Sensitivity_XGB.append(sensitivity)\n",
    "    Specificity_XGB.append(specificity)\n",
    "    Youden_XGB.append(youden_index)\n",
    "    f1_XGB.append(f1score)\n",
    "    gmean_XGB.append(gmean)\n",
    "\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    xgb_fpr_.append(fpr)\n",
    "    xgb_tpr_.append(tpr)\n",
    "    xgb_roc_auc_.append(roc_auc)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    average_precision = average_precision_score(y_test, y_pred_probs)\n",
    "\n",
    "    xgb_precision_.append(precision)\n",
    "    xgb_recall_.append(recall)\n",
    "    xgb_ap_.append(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m, acc_h = np.round(mean_confidence_interval(Accuracy_XGB),3)\n",
    "spe_m, spe_h = np.round(mean_confidence_interval(Specificity_XGB),3)\n",
    "sen_m, sen_h = np.round(mean_confidence_interval(Sensitivity_XGB),3)\n",
    "f1_m, f1_h = np.round(mean_confidence_interval(f1_XGB),3)\n",
    "auroc_m, auroc_h = np.round(mean_confidence_interval(AUROC_XGB),3)\n",
    "ap_m, ap_h = np.round(mean_confidence_interval(AP_XGB),3)\n",
    "gmean_m, gmean_h = np.round(mean_confidence_interval(gmean_XGB),3)\n",
    "\n",
    "# 신뢰구간\n",
    "print(acc_m,'±', acc_h)\n",
    "print(spe_m,'±', spe_h)\n",
    "print(sen_m,'±', sen_h)\n",
    "print(f1_m,'±', f1_h)\n",
    "print(auroc_m,'±', auroc_h)\n",
    "print(ap_m,'±', ap_h)\n",
    "print(gmean_m,'±', gmean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_CATBOOST = []\n",
    "AUROC_CATBOOST = []\n",
    "AP_CATBOOST = []\n",
    "Sensitivity_CATBOOST = []\n",
    "Specificity_CATBOOST = []\n",
    "Youden_CATBOOST = []\n",
    "f1_CATBOOST = []\n",
    "gmean_CATBOOST = []\n",
    "\n",
    "catboost_fpr_ = []\n",
    "catboost_tpr_ = []\n",
    "catboost_roc_auc_ = []\n",
    "\n",
    "catboost_precision_ = []\n",
    "catboost_recall_ = []\n",
    "catboost_ap_ = []\n",
    "\n",
    "for i in range(1,30+1):\n",
    "\n",
    "    exec(f'X_train = X_train_{i}')\n",
    "    exec(f'X_test = X_test_{i}')\n",
    "\n",
    "    exec(f'y_train = y_train_{i}')\n",
    "    exec(f'y_test = y_test_{i}')\n",
    "\n",
    "    exec(f'model = fit_catboost_{i}')\n",
    "\n",
    "    age_mean = np.mean(X_train['AGE'])\n",
    "    age_std = np.std(X_train['AGE'])\n",
    "\n",
    "    X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "    X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "\n",
    "    y_pred_probs = model.predict_proba(X_test)[:,1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1score = f1_score(y_test, y_pred, average='binary')\n",
    "    youden_index = sensitivity + specificity - 1\n",
    "    gmean = geometric_mean_score(y_test, y_pred)\n",
    "\n",
    "    Accuracy_CATBOOST.append(accuracy_score(y_test, y_pred))\n",
    "    AUROC_CATBOOST.append(roc_auc_score(y_test, y_pred_probs))\n",
    "    AP_CATBOOST.append(average_precision_score(y_test, y_pred_probs))\n",
    "    Sensitivity_CATBOOST.append(sensitivity)\n",
    "    Specificity_CATBOOST.append(specificity)\n",
    "    Youden_CATBOOST.append(youden_index)\n",
    "    f1_CATBOOST.append(f1score)\n",
    "    gmean_CATBOOST.append(gmean)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "    catboost_fpr_.append(fpr)\n",
    "    catboost_tpr_.append(tpr)\n",
    "    catboost_roc_auc_.append(roc_auc)\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_pred_probs)\n",
    "    average_precision = average_precision_score(y_test, y_pred_probs)\n",
    "\n",
    "    catboost_precision_.append(precision)\n",
    "    catboost_recall_.append(recall)\n",
    "    catboost_ap_.append(average_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m, acc_h = np.round(mean_confidence_interval(Accuracy_CATBOOST),3)\n",
    "spe_m, spe_h = np.round(mean_confidence_interval(Specificity_CATBOOST),3)\n",
    "sen_m, sen_h = np.round(mean_confidence_interval(Sensitivity_CATBOOST),3)\n",
    "f1_m, f1_h = np.round(mean_confidence_interval(f1_CATBOOST),3)\n",
    "auroc_m, auroc_h = np.round(mean_confidence_interval(AUROC_CATBOOST),3)\n",
    "ap_m, ap_h = np.round(mean_confidence_interval(AP_CATBOOST),3)\n",
    "gmean_m, gmean_h = np.round(mean_confidence_interval(gmean_CATBOOST),3)\n",
    "\n",
    "# 신뢰구간\n",
    "print(acc_m,'±', acc_h)\n",
    "print(spe_m,'±', spe_h)\n",
    "print(sen_m,'±', sen_h)\n",
    "print(f1_m,'±', f1_h)\n",
    "print(auroc_m,'±', auroc_h)\n",
    "print(ap_m,'±', ap_h)\n",
    "print(gmean_m,'±', gmean_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_auroc(model_name):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    for i in range(1,30+1):\n",
    "        \n",
    "        X_train = globals()[f'X_train_{i}']\n",
    "        X_test = globals()[f'X_test_{i}']\n",
    "        \n",
    "        y_train = globals()[f'y_train_{i}']\n",
    "        y_test = globals()[f'y_test_{i}']\n",
    "\n",
    "        classifier = globals()[f'fit_{model_name}_{i}']\n",
    "\n",
    "        age_mean = np.mean(X_train['AGE'])\n",
    "        age_std = np.std(X_train['AGE'])\n",
    "        \n",
    "        X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "        X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "                        \n",
    "        viz = RocCurveDisplay.from_estimator(\n",
    "            classifier,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            ax=ax,)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    ax.plot(0)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_fpr, mean_tpr, mean_auc, std_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_mean_fpr, LR_mean_tpr, LR_mean_auc, LR_std_auc =  mean_auroc(model_name='LR')\n",
    "RF_mean_fpr, RF_mean_tpr, RF_mean_auc, RF_std_auc =  mean_auroc(model_name='rf')\n",
    "CATBOOST_mean_fpr, CATBOOST_mean_tpr, CATBOOST_mean_auc, CATBOOST_std_auc =  mean_auroc(model_name='catboost')\n",
    "XGB_mean_fpr, XGB_mean_tpr, XGB_mean_auc, XGB_std_auc =  mean_auroc(model_name='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'LR':{'mean_fpr': LR_mean_fpr, 'mean_tpr':LR_mean_tpr, 'mean_auc':LR_mean_auc, 'std_auc':LR_std_auc},\n",
    "          'RF':{'mean_fpr': RF_mean_fpr, 'mean_tpr':RF_mean_tpr, 'mean_auc':RF_mean_auc, 'std_auc':RF_std_auc},\n",
    "          'GBM':{'mean_fpr': XGB_mean_fpr, 'mean_tpr':XGB_mean_tpr, 'mean_auc':XGB_mean_auc, 'std_auc':XGB_std_auc},\n",
    "          'Catboost':{'mean_fpr': CATBOOST_mean_fpr, 'mean_tpr':CATBOOST_mean_tpr, 'mean_auc':CATBOOST_mean_auc, 'std_auc':CATBOOST_std_auc}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "for name, values in models.items():\n",
    "    fpr = values['mean_fpr']\n",
    "    tpr = values['mean_tpr']\n",
    "    roc_auc = values['mean_auc']\n",
    "\n",
    "    plt.plot(fpr, tpr, label='%s (AUC = %0.3f)'  % (name, roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "plt.title('ROC curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/figure 1.tiff', format='tiff', dpi=300)  \n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/figure 1.pdf', format='pdf', dpi=300)  \n",
    "plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "for name, values in models.items():\n",
    "    fpr = values['mean_fpr']\n",
    "    tpr = values['mean_tpr']\n",
    "    roc_auc = values['mean_auc']\n",
    "\n",
    "    plt.plot(fpr, tpr, label='%s (AUC = %0.3f)'  % (name, roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "\n",
    "plt.title('ROC curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "\n",
    "# plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/figure 1.tiff', format='tiff', dpi=300)  \n",
    "# plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/figure 1.pdf', format='pdf', dpi=300)  \n",
    "# plt.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap : risk factor analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = pickle.load(open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/LR/fit_LR_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_1\n",
    "X_test = X_test_1\n",
    "\n",
    "y_train = y_train_1\n",
    "y_test = y_test_1\n",
    "\n",
    "age_mean = np.mean(X_train['AGE'])\n",
    "age_std = np.std(X_train['AGE'])\n",
    "\n",
    "X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "\n",
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_function = lambda X: LR_model.fit(X_train, y_train).predict_proba(X)[:,1]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_proba_function, shap.sample(X_train, 1000))\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_LR = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as pickle file\n",
    "with open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_values_LR.pkl', 'wb') as file:\n",
    "    pickle.dump(shap_values_LR, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_LR, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "shap.summary_plot(shap_values_LR, X_test, show=False)  \n",
    "\n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_LR.tiff', format='tiff', dpi=300)  \n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_LR.pdf', format='pdf', dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pickle.load(open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/RF/fit_rf_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_1\n",
    "X_test = X_test_1\n",
    "\n",
    "y_train = y_train_1\n",
    "y_test = y_test_1\n",
    "\n",
    "age_mean = np.mean(X_train['AGE'])\n",
    "age_std = np.std(X_train['AGE'])\n",
    "\n",
    "X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_function = lambda X: rf_model.fit(X_train, y_train).predict_proba(X)[:,1]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_proba_function, shap.sample(X_train, 1000))\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_rf = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as pickle file\n",
    "with open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_values_rf.pkl', 'wb') as file:\n",
    "    pickle.dump(shap_values_rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_rf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "shap.summary_plot(shap_values_rf, X_test, show=False)  \n",
    "\n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_rf.tiff', format='tiff', dpi=300)  \n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_rf.pdf', format='pdf', dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = pickle.load(open('C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/model pkl save/XGB/fit_xgb_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_1\n",
    "X_test = X_test_1\n",
    "\n",
    "y_train = y_train_1\n",
    "y_test = y_test_1\n",
    "\n",
    "age_mean = np.mean(X_train['AGE'])\n",
    "age_std = np.std(X_train['AGE'])\n",
    "\n",
    "X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_function = lambda X: xgb_model.fit(X_train, y_train).predict_proba(X)[:,1]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_proba_function, shap.sample(X_train, 1000))\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_xgb = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as pickle file\n",
    "with open('C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/shap/shap_values_xgb.pkl', 'wb') as file:\n",
    "    pickle.dump(shap_values_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_xgb, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "shap.summary_plot(shap_values_xgb, X_test, show=False)  \n",
    "\n",
    "plt.savefig('C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/shap/shap_summary_plot_xgb.tiff', format='tiff', dpi=300)  \n",
    "plt.savefig('C:/Users/chaehyun/Dropbox/Work/PIPET/과제/산부인과/난소암 연구/Analysis dataset/Data for WS/[24-12-12]/subgroup analysis/hr/shap/shap_summary_plot_xgb.pdf', format='pdf', dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = pickle.load(open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/model pkl save/Catboost/fit_catboost_1.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_1\n",
    "X_test = X_test_1\n",
    "\n",
    "y_train = y_train_1\n",
    "y_test = y_test_1\n",
    "\n",
    "age_mean = np.mean(X_train['AGE'])\n",
    "age_std = np.std(X_train['AGE'])\n",
    "\n",
    "X_train['AGE'] = (X_train['AGE'] - age_mean) / age_std\n",
    "X_test['AGE'] = (X_test['AGE'] - age_mean) / age_std\n",
    "\n",
    "catboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_function = lambda X: catboost_model.fit(X_train, y_train).predict_proba(X)[:,1]\n",
    "\n",
    "explainer = shap.KernelExplainer(predict_proba_function, shap.sample(X_train, 1000))\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_catboost = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as pickle file\n",
    "with open('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_values_catboost.pkl', 'wb') as file:\n",
    "    pickle.dump(shap_values_catboost, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_catboost, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "\n",
    "shap.summary_plot(shap_values_catboost, X_test, show=False)  \n",
    "\n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_catboost.tiff', format='tiff', dpi=300)  \n",
    "plt.savefig('/camin1/chlee/jupyter/ML project/[24-12-13]/subgroup analysis/hr/shap/shap_summary_plot_catboost.pdf', format='pdf', dpi=300) \n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ovcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
